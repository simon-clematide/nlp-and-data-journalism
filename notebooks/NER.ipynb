{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_N0WT8hoEfkL"
   },
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "Entity Recognition means detecting the following in raw text: people, company names, locations and many other types of named entities. After finding entities in the text, we would like to display them nicely. Here is an example of our goal:\n",
    "\n",
    "![ner example](https://files.ifi.uzh.ch/cl/archiv/2019/tamedia/ner.png)\n",
    "\n",
    "In the example above, people, organizations and dates are highlighted. Our goal is to identifiy those entities _automatically_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcupIDsBEfkr"
   },
   "source": [
    "## 1 Web Demos as Warm Up\n",
    "\n",
    "Before we analyze entities in our own data, let's briefly look at some demos of existing services that showcase nicely the potential and limits.\n",
    "\n",
    "**Dandelion API**: https://dandelion.eu/semantic-text/entity-extraction-demo\n",
    "\n",
    "Notable features: supports many languages, users can choose between recognizing more entities or higher precision. Entities are not only recognized, but also _linked_ to more information, such as images or Wiki articles.\n",
    "\n",
    "**Explosion DisplaCy**: https://demos.explosion.ai/displacy-ent/\n",
    "\n",
    "Notable features: users can select which classes should be recognized. Also supports several languages and is transparent about which model is used in the background. Generates HTML and CSS at the bottom that can be copy-pasted into any web page. Entirely open-source, too!\n",
    "\n",
    "**Tasks:**\n",
    "- **Try those web demos with your own texts.**\n",
    "- **Try several languages.**\n",
    "- **How would you rate the quality of named entity recognition?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EfP9Tk5dHKaM"
   },
   "source": [
    "## 2 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "EybjHGlMHAWC",
    "outputId": "03090a59-5828-4bda-ac23-b961c843627d"
   },
   "outputs": [],
   "source": [
    "! pip install requests spacy spacy-lookups-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oUQPftpxHSDH",
    "outputId": "7f688e6b-585a-4057-c95e-1cf7d1a90605"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download de_core_news_md\n",
    "!python -m spacy download fr_core_news_md\n",
    "\n",
    "! python -m spacy link --force de_core_news_md de_core_news_md\n",
    "! python -m spacy link --force fr_core_news_sm fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADBKol6av0IG"
   },
   "outputs": [],
   "source": [
    "# Alternatively, if the above does not work (if models cannot be found after installation was successful)\n",
    "\n",
    "#! pip install https://github.com/explosion/spacy-models/releases/download/de_core_news_md-2.2.5/de_core_news_md-2.2.5.tar.gz\n",
    "#! pip install https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQNBh4itJuzu"
   },
   "source": [
    "Download data (parliament transcriptions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "bs86qYb-Jwm4",
    "outputId": "a78fc8a2-7b9b-4fe9-ce81-c5c31ae973fe"
   },
   "outputs": [],
   "source": [
    "! wget https://files.ifi.uzh.ch/cl/siclemat/lehre/hs19/tm/parlament_transcriptions.jsonl.bz2\n",
    "! bzip2 -d parlament_transcriptions.jsonl.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LJFxbKojKOAx",
    "outputId": "0d0ae788-551b-4f0a-b457-4cbb92157aed"
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "l03FWty1LALI",
    "outputId": "9a4ca83a-8b72-4805-97af-31ba3678bc46"
   },
   "outputs": [],
   "source": [
    "! head parlament_transcriptions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "ocdOdxNgLa_l",
    "outputId": "0c20a65c-d727-467b-8461-19c9c13a216b"
   },
   "outputs": [],
   "source": [
    "! grep \"SVP\" parlament_transcriptions.jsonl | head -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjAa-mBHHSFt"
   },
   "source": [
    "## 3 Pre-trained models with spaCy\n",
    "\n",
    "Named entity recognition is a _supervised classification task_ that requires training data to learn from. In this section, instead of training an NER model, we will use a pre-trained model from the NLP library spaCy.\n",
    "\n",
    "After importing spaCy, load a specific pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmiciUGeFk-4"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8x9zCGvorIry"
   },
   "source": [
    "Which returns a function, `nlp`, which can be called with a string to be analyzed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "9NsGvAx7Gck1",
    "outputId": "2f698d59-e748-4b94-9a62-d367dafe8395"
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"(Seiler Hanspeter, Präsident): Die sozialdemokratische Fraktion, unterstützt von der freisinnig-demokratischen, der SVP-, der christlichdemokratischen, der evangelischen und unabhängigen Fraktion, schlägt Ihnen Frau Maury Pasquier vor.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2f0oYqhxrQbB"
   },
   "source": [
    "In this text, spaCy has recognized PER, ORG and MISC entities. See https://spacy.io/api/annotation#named-entities for all kinds of entities spaCy knows about.\n",
    "\n",
    "SpaCy also includes very helpful code to visualize results, in the sub-package `displacy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LKuOViasQfj5",
    "outputId": "5684110f-d696-4a7a-c6a4-bbbc67b783fa"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2ogGujDRSXH"
   },
   "source": [
    "**Tasks:**\n",
    "\n",
    "- **Recognize entities in parliament speeches with a pre-trained spaCy model.**\n",
    "- **Use the German and/or French spaCy models to recognize named entities in parliament speeches, and display them with displacy.**\n",
    "- **The data file should be on your machine already, `parlament_transcriptions.jsonl`.**\n",
    "\n",
    "<details>\n",
    "<summary>If you are stuck: click to see more specific instructions.</summary>\n",
    "\n",
    "- Important: Start to experiment with a _small number of examples_, for instance the top 100 lines in the input file.\n",
    "- Use Python's standard library package `json` to read in JSON lines from the file, for instance with `DictReader`.\n",
    "- Make sure you use the JSON key `Language` to decide whether lines are German or French. The JSON key `Text` holds the actual text content.\n",
    "- The actual content contains XML or HTML tags. Remove those tags before analyzing the strings with SpaCy. Some ways to remove the HTML: regexes, `lxml`,`BeautifulSoup`.\n",
    "- To analyze documents in a loop, use spaCy's _pipeline_ feature that returns a generator to loop over:\n",
    "\n",
    "```python\n",
    "for doc in nlp.pipeline(texts):\n",
    "  # process individual Doc element\n",
    "```\n",
    "- When calling `nlp` with an input text, disable steps that are not needed for NER, to make processing much faster:\n",
    "\n",
    "```python\n",
    "for doc in nlp.pipeline(texts, disable=[\"tagger\", \"parser\"]):\n",
    "  # process individual Doc element\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpPvm0mLuAY4"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRDsRZdXEfmj"
   },
   "source": [
    "## 4 Train from scratch or extend an NER model with spaCy\n",
    "\n",
    "Instead of using a pre-trained model, we can of course train our own model. **This requires labelled training examples that contain the \"right\" answers**.\n",
    "\n",
    "For the sake of this exercise, we will assume that there is a need to add a new class to our label set. To adapt to our target text domain, we will add the class label (political) `PARTY`.\n",
    "\n",
    "### Training data format\n",
    "\n",
    "NLP tools require training data to be in a specific format. In the case of NER, training examples must be structured as follows:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>TEXT</th>\n",
    "<th>ENTITY</th>\n",
    "<th>START</th>\n",
    "<th>END</th>\n",
    "<th>LABEL</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>(Seiler Hanspeter, Präsident):</td>\n",
    "<td>Seiler Hanspeter</td>\n",
    "<td>1</td>\n",
    "<td>16</td>\n",
    "<td>PERSON</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>(Seiler Hanspeter, Präsident):</td>\n",
    "<td>Präsident</td>\n",
    "<td>19</td>\n",
    "<td>27</td>\n",
    "<td>TITLE</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "START and END are character offsets into the string, ENTITY is just the substring identified by those offsets, for convenience. The specific format can vary, but it must be clear 1) which exact span of text is being labelled and 2) which class label is assigned to this span.\n",
    "\n",
    "In the case of spaCy, the exact format that training data need to be in is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Crf0CFv-OqZw"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "        (\"(Seiler Hanspeter, Präsident):\", {\"entities\": [(1, 16, \"PERSON\")]}),\n",
    "        (\"(Seiler Hanspeter, Präsident):\", {\"entities\": [(19, 27, \"TITLE\")]})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWXboXOCOqsE"
   },
   "source": [
    "**Tasks:**\n",
    "- **We are adding to our model a new label, `PARTY`. Look at our collection of speeches to find some examples you would label as `PARTY`.**\n",
    "- **In your opinion, can we create the training data automatically? After all, we know the names of most political parties involved.**\n",
    "- **Create some new training data, automatically (100 examples) or manually (10 examples).**\n",
    "\n",
    "<details>\n",
    "<summary>If you are stuck: click to see more specific instructions.</summary>\n",
    "\n",
    "- Define keywords that identify different parties, store them in a Python dict.\n",
    "- Loop over all our training data examples, for instance by analyzing documents to segment them into sentences:\n",
    "```python\n",
    "doc = nlp(\"Nur ganz kurz: Bei diesem Artikel geht es um die Frage des Übergangsrechtes. Die SVP-Fraktion unterstützt die Minderheit Baumann Alexander einstimmig.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "```\n",
    "- Go over all tokens in a sentence. If a token is one of your pre-defined keywords, save this sentence as a training example, together with START, END and LABEL of the token.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Poyk19ptvIcf"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "soDrcLr7cFl6"
   },
   "source": [
    "### Continue training with additional data\n",
    "\n",
    "The following code assumes that you have compiled a list of additional training examples, in the variable `TRAIN_DATA`.\n",
    "\n",
    "To do the continued training, also called _fine-tuning_, we will adapt code from the [superb spaCy documentation](https://spacy.io/usage/training#example-new-entity-type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFQDxpgLfXMa"
   },
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# new entity label\n",
    "LABEL = \"ANIMAL\"\n",
    "\n",
    "@plac.annotations(\n",
    "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "    new_model_name=(\"New model name for model meta.\", \"option\", \"nm\", str),\n",
    "    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
    ")\n",
    "def main(model=None, new_model_name=\"animal\", output_dir=None, n_iter=30):\n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    random.seed(0)\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    ner.add_label(LABEL)  # add new entity label to entity recognizer\n",
    "    # Adding extraneous labels shouldn't mess anything up\n",
    "    ner.add_label(\"VEGETABLE\")\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            batches = minibatch(TRAIN_DATA, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "\n",
    "    # test the trained model\n",
    "    test_text = \"Do you like horses?\"\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, ent.text)\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta[\"name\"] = new_model_name  # rename model\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        # Check the classes have loaded back consistently\n",
    "        assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "        doc2 = nlp2(test_text)\n",
    "        for ent in doc2.ents:\n",
    "            print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgvkBSt9gPX9"
   },
   "source": [
    "**Tasks:**\n",
    "\n",
    "- **Check out the link to spaCy documentation above for more explanations of all the steps above.**\n",
    "- **Adapt the code to our needs, in order for the model to recognize the additional label `PARTY`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKvccmeZg_rh"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkZaQ3TOdeou"
   },
   "source": [
    "### Combat catastrophic forgetting (Bonus Section)\n",
    "\n",
    "Continuing to train with this method is prone to _catastrophic forgetting_: if a model is only shown examples with the new label during training, it might forget how to recognize the original set of entities.\n",
    "\n",
    "One way to avoid this problem is to also show examples with the labels from the first training phase during the second training. Since we do not have access to the original training set, we can use the model to predict the labels for our own data set.\n",
    "\n",
    "**Additional Tasks:**\n",
    "- **Run the trained model on some of our parliament data, to create some examples for known labels such as `ORG` and `PERSON`.**\n",
    "- **Mix those training examples with the ones created for `PARTY`, then continue training the model on this combined data set.**\n",
    "\n",
    "<details>\n",
    "<summary>If you are stuck: click to see more specific instructions.</summary>\n",
    "\n",
    "- Use a loaded spaCy model (that we usually call `nlp`) to analyze input texts. The resulting variable has an attribute `ents` that contains a list of all recognized entities, and each entity contains START, END and LABEL:\n",
    "```python\n",
    "doc = nlp(\"Example text with Obama.\")\n",
    "for ent in doc.ents:\n",
    "  print(ent.start_char, ent.end_char, ent.label_)\n",
    "```\n",
    "- If you are _really_ stuck, read through https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting for a walk-through and explanations of _pseudo rehearsal_.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oHJpNhNexSM"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8C7S_44P2uS"
   },
   "source": [
    "## 5 Combine a pre-trained statistical model with rule-based extraction\n",
    "\n",
    "Instead of creating more training data and fine-tuning an existing model, an alternative approach is to complement a trained statistical model with **hand-written rules**. The resulting model is called a **hybrid**, and the improvements over a statistical baseline can be substantial.\n",
    "\n",
    "Here are some examples for rules:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>IF</th>\n",
    "<th>THEN</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Token is 'SVP' or 'svp'</td>\n",
    "<td>class is \"PARTY\"</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Token contains 'Fraktion'</td>\n",
    "<td>class is \"PARTY\"</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gUMNWQNP8tH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLK6Q6VTWiYB"
   },
   "source": [
    "## 6 Further Reading and Links\n",
    "\n",
    "- spaCy documentation: https://spacy.io/\n",
    "- Course with self-test exercises: https://course.spacy.io/\n",
    "- In-depth explanations of spaCy's NER model: https://www.youtube.com/watch?v=sqDHBH9IjRU. In a nutshell, spaCy uses embeddings with subword features, and processes them with deep convolutional neural networks with residual connections.\n",
    "\n",
    "Do you have feedback, corrections, suggestions to improve this notebook? Please write an email to mmueller@cl.uzh.ch. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJOu-HLCXMdK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
